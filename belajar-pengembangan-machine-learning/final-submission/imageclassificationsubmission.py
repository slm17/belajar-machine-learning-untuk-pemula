# -*- coding: utf-8 -*-
"""ImageClassificationSubmission.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1M3lSwvJED3Gwlssv1sdB1IAb2tUAwgm8
"""

# Commented out IPython magic to ensure Python compatibility.
# import library yang dibutuhkan
import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator

import sklearn
from sklearn import datasets
from sklearn.model_selection import train_test_split
import zipfile,os
import os

import numpy as np
from google.colab import files
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline
from tensorflow.keras.models import Sequential

import os
os.environ['KAGGLE_USERNAME'] = 'TYPE YOUR USERNAME'
os.environ['KAGGLE_KEY'] = 'TYPE YOUR KAGGLE KEY'

!kaggle datasets download -d ashishjangra27/face-mask-12k-images-dataset

!unzip -q face-mask-12k-images-dataset

base_dir = '/content/Face Mask Dataset/Train'

print('With Mask: ', len(os.listdir('/content/Face Mask Dataset/Train/WithMask')))
print('Without Mask: ', len(os.listdir('/content/Face Mask Dataset/Train/WithoutMask')))

img = image.load_img('/content/Face Mask Dataset/Train/WithMask/10.png')
imgplot = plt.imshow(img)

train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    horizontal_flip=True,
    width_shift_range=0.2,
    height_shift_range=0.2,
    zoom_range=0.2,
    fill_mode='nearest',
    validation_split=0.2)

train_generator = train_datagen.flow_from_directory(
        base_dir, # direktori data latih
        shuffle=True,
        target_size=(150,150),
        class_mode='categorical',
        subset='training')

validation_generator = train_datagen.flow_from_directory(
        base_dir, # direktori data validasi
        shuffle=True,
        target_size=(150,150),
        class_mode='categorical',
        subset='validation')

# create model
model = tf.keras.models.Sequential([
    # Note the input shape is the desired size of the image 150x150 with 3 bytes color
    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.4),  
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), 
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Dropout(0.4),  
    # Flatten the results to feed into a DNN
    tf.keras.layers.Flatten(), 
    # 512 neuron hidden layer
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(2, activation='softmax')  
])

model.summary()

# callback
class mCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('val_accuracy')>0.97):
      print('\nPelatihan dihentikan, Akurasi lebih dari 97% !')
      self.model.stop_training = True

callbacks = mCallback()

model.compile(optimizer=tf.optimizers.Adam(),
              loss='categorical_crossentropy',
              metrics = ['accuracy'])

history = model.fit(train_generator,
      steps_per_epoch=25,
      epochs=50,
      validation_data=validation_generator,
      validation_steps=5,
      verbose=2,
      callbacks=[callbacks])

# plot loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper right')
plt.show()

# plot accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Akurasi Model')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# PREDICTIONS
uploaded = files.upload()
for fn in uploaded.keys():

  # predicting images
  path = fn
  img = image.load_img(path, target_size=(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)

  images = np.vstack([x])
  classes = model.predict(images, batch_size=10)

  print(fn)
  if classes[0][0]==1:
    print('Without Mask')
  elif classes[0][1]==1:
    print('With Mask')
  else:
    print('Unrecognized')

# model convert
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

with tf.io.gfile.GFile('model.tflite', 'wb') as f:
  f.write(tflite_model)