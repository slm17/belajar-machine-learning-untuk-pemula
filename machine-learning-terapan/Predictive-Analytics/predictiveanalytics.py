# -*- coding: utf-8 -*-
"""PredictiveAnalytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xBu-yDxUBTiLdXcTDHuwFuJ99uOfSkQF

import library
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns
import zipfile,os

import os
os.environ['KAGGLE_USERNAME'] = 'sulaimann'
os.environ['KAGGLE_KEY'] = '88952eb3c31573d4ef92c24dbb078df4'

"""download dataset 

sumber dataset https://www.kaggle.com/nehalbirla/vehicle-dataset-from-cardekho
"""

!kaggle datasets download -d nehalbirla/vehicle-dataset-from-cardekho

"""unzip dataset"""

!unzip vehicle-dataset-from-cardekho

"""masukkan data ke variabel cars"""

cars = pd.read_csv('/content/Car details v3.csv')
cars

"""output diatas memberikan informasi sebagai berikut:
- ada 8128 baris(records atau jumlah pengamatan) dalam dataset
- terdapat 13 kolom yaitu: name year selling_price km_driven	fuel	seller_type transmission owner	mileage engine max_power torque seats

Deskripsi Variabel
1. name: nama mobil
2. year: tahun pembelian mobil
3. selling_price: harga yang diinginkan pemilik untuk menjual mobil
4. km_driven: jumlah kilometer yang ditempuh mobil tersebut
5. fuel: jenis bahan bakar mobil(Diesel/Petrol)
6. seller_type: mobil yang dijual oleh (individu/dealer)
7. transmission: transmisi gigi mobil (Automatic/Manual)
8. owner: kepemilikan mobil
9. mileage: jarak tempuh mobil
10. engine: kapasitas mesin mobil
11. max_power: tenaga maksimal mobil
12. torque: torsi mobil
13. seats: jumlah penumpang

menambahkan variabel tahun yang berisikan 2021 adalah tahun saat model ini di buat
"""

cars['current'] = 2021

"""menambahkan variabel age untuk kolom usia mobil"""

cars['age']=cars['current']-cars['year']

"""hapus kolom yang tidak di butuhkan"""

cars.drop(['current','year','name','mileage','engine','max_power','torque','seats'],axis=1,inplace=True)
cars.head()

"""cek informasi pada dataset"""

cars.info()

"""Dari output di atas dapat dilihat bahwa:
- terdapat 4 kolom dengan tipe object, yaitu: furl, seller_type, trasmission, owner. kolom ini merupakan categorical features(fitur non-numerik)
- terdapat 3 kolom numerik dengan tipe int64, yaitu: selling_price, km_driven, age. kolom ini merupakan numerical features(fitur numerik)

cek ukuran data
"""

cars.shape

"""cek data kosong"""

cars.isnull().sum()

"""cek deskripsi statistik data"""

cars.describe()

"""fungsi describe() memberikan informasi statistik pada masing-masing kolom , antara lain:
- count adalah jumlah sampel pada data
- mean adalah nilai rata-rata
- std adalah standar deviasi
- min adalah nilai minimum setiap kolom
- 25% adalah kuartil pertama. kuartil adalah nilai yang menandai batas interval dalam empat bagian yang sama
- 50% adalah kuartil kedua, atau juga bisa di sebut median(nilai tengah)
- 75% adalah kuartil ketiga
- max adalah nilai maksimum

**Menangani Outliers**

menggunakan teknik teknik visualisasi data.


visualisasi pada fitur numerik
- selling_price
- km_driven
- age

1. fitur selling price
"""

sns.boxplot(x=cars['selling_price'])

"""2. fitur km_driven"""

sns.boxplot(x=cars['km_driven'])

"""3. fitur age"""

sns.boxplot(x=cars['age'])

"""drop outliners dan cek ukuran dataset"""

Q1 = cars.quantile(0.25)
Q3 = cars.quantile(0.75)
IQR=Q3-Q1
carss=cars[~((cars<(Q1-1.5*IQR))|(cars>(Q3+1.5*IQR))).any(axis=1)]
     
cars.shape

"""### Exploratory Data Analysis

#### Univariate Analysis

---


proses analisis data dengan teknik Univariate EDA. Pertama, bagi fitur pada dataset menjadi dua bagian, yaitu numerical features dan categorical features.
"""

numerical_feature = ['selling_price','km_driven','age']
categorical_feature = ['fuel','seller_type','owner']

"""Categorical Features
- bahan bakar
- seller_type
- owner

1. fitur bahan bakar
"""

feature = categorical_feature[0]
count = carss[feature].value_counts()
percent = 100*cars[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""2. fitur seller type"""

feature = categorical_feature[1]
count = carss[feature].value_counts()
percent = 100*cars[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""3. fitur owner"""

feature = categorical_feature[2]
count = carss[feature].value_counts()
percent = 100*cars[feature].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
count.plot(kind='bar', title=feature);

"""Numerical Features

melihat histogram di masing-masing fitur


"""

cars.hist(bins=50, figsize=(20,15))
plt.show()

"""#### Multivariate Analysis


---


Multivariate EDA menunjukkan hubungan antara dua atau lebih variabel pada data. Multivariate EDA yang menunjukkan hubungan antara dua variabel biasa disebut sebagai bivariate EDA.


---


Melakukan analisis data pada fitur kategori dan numerik

**Categorical Features**

cek rata-rata harga terhadap masing-masing fitur untuk mengetahui pengaruh fitur kategori terhadap harga
"""

cat_features = cars.select_dtypes(include='object').columns.to_list()

for col in cat_features:
  sns.catplot(x=col, y="selling_price", kind="bar", dodge=False, height=4, aspect=3, data=cars, palette="Set3")
  plt.title("Rata-rata 'selling_price' Relatif terhadap - {}".format(col))

"""**Numerical Features**

observasi korelasi antara fitur numerik dengan fitur target menggunakan fungsi corr()

mengamati hubungan antar fitur numerik dengan fungsi pairplot()
"""

sns.pairplot(cars, diag_kind = 'kde')

plt.figure(figsize=(10, 8))
correlation_matrix = cars.corr().round(2)
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""# Data Preparation


---

Data Preparation pada proyek ini berfungsi untuk mentransformasi pada data sehingga menjadi bentuk yang cocok untuk proses permodelan

1.   Encoding fitur kategori.
2.   Pembagian dataset dengan fungsi train_test_split dari library sklearn.
3.   Standarisasi.

**1. Encoding Fitur Kategori**

One-Hot Encoding adalah teknik yang merubah setiap nilai di dalam kolom menjadi kolom baru dan mengisinya dengan nilai biner dari variabel kategori ke variabel numerik menjadi 0 dan 1. One-hot-encoding berfungsi untuk mendapatkan fitur baru yang sesuai sehingga dapat mewakili variabel kategori.
"""

from sklearn.preprocessing import  OneHotEncoder
cars = pd.concat([cars, pd.get_dummies(cars['fuel'], prefix='fuel', drop_first=True)],axis=1)
cars = pd.concat([cars, pd.get_dummies(cars['seller_type'], prefix='seller_type', drop_first=True)],axis=1)
cars = pd.concat([cars, pd.get_dummies(cars['transmission'], prefix='transmission', drop_first=True)],axis=1)
cars = pd.concat([cars, pd.get_dummies(cars['owner'], prefix='owner', drop_first=True)],axis=1)
cars.drop(['fuel','seller_type','transmission','owner'], axis=1, inplace=True)
cars.head()

"""**2. Train Test Split**

Membagi dataset menjadi data latih (train) dan data uji (test)
    - Data Train: Sebagai data yang digunakan model untuk belajar pola yang dimiliki data
    - Data Test: Berguna untuk memahami model kita bekerja di kondisi sesungguhnya (real-life situation)
    
Pentingnya proses ini karena dalam Machine Learning, hal yang kita pedulikan adalah seberapa baik kinerja model ketika dihadapkan pada data yang belum pernah dilihat sebelumnya. Oleh karena itulah, kita selalu melatih dan menguji model menggunakan dua data yang berbeda.
"""

from sklearn.model_selection import train_test_split
     
X = cars.drop(["selling_price"],axis =1)
y = cars["selling_price"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 123)

"""cek jumlah sample"""

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""**3. Standarisasi**

Standarisasi membantu untuk membuat fitur data menjadi bentuk yang lebih mudah diolah oleh algoritma. Melakukan proses standarisasi setelah proses pembagian data train dan data test berguna untuk menghindari kebocoran informasi pada data uji, dengan menerapkan fitur standarisasi pada data latih.

Menggunakan teknik StandarScaler dari library Scikitlearn, StandardScaler melakukan proses standarisasi fitur dengan mengurangkan mean (nilai rata-rata) kemudian membaginya dengan standar deviasi untuk menggeser distribusi.
"""

from sklearn.preprocessing import StandardScaler
     
numerical_features = ['km_driven', 'age']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

"""cek nilai mean dan standar deviasi"""

X_train[numerical_features].describe().round(3)

"""# Modeling

Menggunakan 3 Algoritma Machine Learning antara lain Random Forest, KNN(K-Nearest Neighhbor), Boosting Algorithm, kemudian membandingkan performanya.


---


- KNN(K-Nearest Neighhbor)

KNN bekerja dengan membandingkan jarak satu sampel ke sampel pelatihan lain dengan memilih sejumlah k-tetangga terdekat
- Random Forest

Random Forest berawal dari memecah data sampel yang ada kedalam decision tree secara acak. Setelah pohon terbentuk,maka akan dilakukan voting pada setiap kelas dari data sampel. Kemudian, mengkombinasikan vote dari setiap kelas kemudian diambil vote yang paling banyak.
- Boostiing Algorithm

Boosting Algorithm bekerja dengan membangun model dari data latih. Kemudian ia membuat model kedua yang bertugas memperbaiki kesalahan dari model pertama. Model ditambahkan sampai data latih terprediksi dengan baik atau telah mencapai jumlah maksimum model untuk ditambahkan.

Siapkan dataframe
"""

models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['KNN', 'RandomForest', 'Boosting'])

"""Latih dataset dengan algoritma KNN"""

from sklearn.neighbors import KNeighborsRegressor

knn = KNeighborsRegressor(n_neighbors=10)
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_train)

"""Latih dataset dengan algoritma Random Forest"""

from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestRegressor

RF = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train)
 
models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""Latih dataset dengan algoritma Boosting Algorithm"""

from sklearn.ensemble import AdaBoostRegressor
     
boosting = AdaBoostRegressor(n_estimators=50, learning_rate=0.05, random_state=55)                             
boosting.fit(X_train, y_train)
models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""# Evaluation


---


metrik yang akan kita gunakan pada prediksi ini adalah MSE atau Mean Squared Error yang menghitung selisih rata-rata nilai sebenarnya dengan nilai prediksi

Proses scaling terhadap data uji
"""

X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

"""evaluasi model dengan metrix MSE"""

mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])
model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting}
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3 
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3
 
mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""Dari gambar di atas, terlihat bahwa, model KNN memberikan nilai eror yang paling kecil. Model inilah yang akan kita pilih sebagai model terbaik untuk melakukan prediksi harga mobil

# Pengujian

---
"""

prediksi = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)
     
pd.DataFrame(pred_dict)